{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking1\n",
    "在CTR点击率预估中，使用GBDT+LR的原理是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：（1）利用GBDT对特征进行转换，增加特征维度：取训练集中的部分样本通过GBDT串行地训练出多棵树，记训练完成后所有叶子节点的个数为k，对于训练集中其余的样本利用训练好的GBDT进行预测，将其所属的叶子节点位置处记为1，非所属的叶子节点处记为0，拼接每棵树所得的向量后，将最终得到k维的向量作为特征向量；  \n",
    "&emsp;&emsp;（2）利用LR对完成特征转换的这部分训练集进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking2\n",
    "Wide & Deep的模型结构是怎样的，为什么能通过具备记忆和泛化能力（memorization and generalization）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：Wide&Deep的Wide部分是由线性回归模型构成，其中如需考虑特征组合则需要人为构造，Deep部分则由DNN模型构成，在训练过程中同时考虑Wide模型和Deep模型以及加权和来优化所有参数。Wide&Deep的模型结构结合了线性模型的记忆能力，即直接利用历史数据学习特征或物品的共现性，以及DNN模型的泛化能力，即通过特征相关性的传递，发掘那些历史数据中没有出现过的特征组合，使模型具有推理能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking3\n",
    "在CTR预估中，使用FM与DNN结合的方式，有哪些结合的方式，代表模型有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：（1）并行结构，FM和DNN分开计算：DeepFM；  \n",
    "&emsp;&emsp;（2）串行结构，将FM的结果作为DNN输入：NFM。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking4\n",
    "GBDT和随机森林都是基于树的算法，它们有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：（1）在选择样本时：GBDT每次训练的样本是固定的，而随机森林每次训练的样本是从总训练样本中随机有放回抽样得到的；  \n",
    "&emsp;&emsp;（2）在生成树时：GBDT每次在上一颗树预测结果残差减小的方向上生成下一棵树，每棵树都对全部特征进行考量，树与树之间并非独立，串行生成，而随机森林每棵树都是随机选取部分特征，树与树之间相互独立，并行生成的；  \n",
    "&emsp;&emsp;（3）在预测时：GBDT是将预测样本在每颗树上所属叶子节点的值相加得到最终结果，随机森林是对所有树预测结果进行投票得到最终结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking5\n",
    "item流行度在推荐系统中有怎样的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：（1）解决冷启动问题：根据流行度找到系统中的热门商品，对新用户进行推荐；  \n",
    "&emsp;&emsp;（2）在个性化推荐时可以将流行度作为惩罚，因为太热门商品可能会烂俗，缺乏个性化，或者在如婚恋网站等一些情形下不适合使用热门推荐。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action1\n",
    "使用Wide&Deep模型对movielens进行评分预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        2     3.5  1112486027\n",
       "1       1       29     3.5  1112484676\n",
       "2       1       32     3.5  1112484819\n",
       "3       1       47     3.5  1112484727\n",
       "4       1       50     3.5  1112484580"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 载入数据\n",
    "data = pd.read_csv('ratings.csv')\n",
    "\n",
    "# 数据探索\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>340880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3.5</td>\n",
       "      <td>340785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3.5</td>\n",
       "      <td>340801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.5</td>\n",
       "      <td>340790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3.5</td>\n",
       "      <td>340774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       0        1     3.5     340880\n",
       "1       0       28     3.5     340785\n",
       "2       0       31     3.5     340801\n",
       "3       0       46     3.5     340790\n",
       "4       0       49     3.5     340774"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "sparse_features = ['userId', 'movieId', 'timestamp']\n",
    "target = ['rating']\n",
    "for feature in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feature] = lbe.fit_transform(data[feature])\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseFeat(name='userId', vocabulary_size=7120, embedding_dim=8, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x000001B609525CD0>, embedding_name='userId', group_name='default_group', trainable=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepctr.feature_column import SparseFeat, get_feature_names\n",
    "fixlen_feature_columns = [SparseFeat(feature, data[feature].nunique(), embedding_dim=8) for feature in sparse_features]\n",
    "fixlen_feature_columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId', 'movieId', 'timestamp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定LR和DNN训练所使用的特征列，并获取列名\n",
    "DNN_columns = fixlen_feature_columns\n",
    "LR_columns = fixlen_feature_columns\n",
    "feature_names = get_feature_names(DNN_columns + LR_columns)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\80566\\Coding\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:431: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622/2622 [==============================] - 156s 60ms/step - loss: 0.9398 - mse: 0.9300 - val_loss: 0.7536 - val_mse: 0.7340\n",
      "Epoch 2/5\n",
      "2622/2622 [==============================] - 158s 60ms/step - loss: 0.3888 - mse: 0.3591 - val_loss: 0.8028 - val_mse: 0.7603\n",
      "Epoch 3/5\n",
      "2622/2622 [==============================] - 153s 58ms/step - loss: 0.4616 - mse: 0.4104 - val_loss: 0.8298 - val_mse: 0.7690\n",
      "Epoch 4/5\n",
      "2622/2622 [==============================] - 157s 60ms/step - loss: 0.3502 - mse: 0.2893 - val_loss: 0.8436 - val_mse: 0.7810\n",
      "Epoch 5/5\n",
      "2622/2622 [==============================] - 156s 59ms/step - loss: 0.2789 - mse: 0.2196 - val_loss: 0.8446 - val_mse: 0.7861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr.models import WDL\n",
    "\n",
    "# 切分数据集\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_input = {name: train[name].values for name in feature_names}\n",
    "test_input = {name: test[name].values for name in feature_names}\n",
    "\n",
    "# 使用WDL进行训练\n",
    "model = WDL(LR_columns, DNN_columns, task='regression')\n",
    "model.compile('adam', 'mse', metrics=['mse'])\n",
    "history = model.fit(train_input, train[target].values, batch_size=256, epochs=5, verbose=1, validation_split=0.2, )\n",
    "pred = model.predict(test_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE: 0.8880878334939625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = round(mean_squared_error(test[target].values, pred), 4)\n",
    "rmse = mse**0.5\n",
    "print('test RMSE:', rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
