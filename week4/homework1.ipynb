{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking1\n",
    "ALS都有哪些应用场景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：ALS可以应用在电影推荐（基于评分等显示行为数据的ALS），商品推荐、广告推送（基于浏览、点击等隐式行为数据的ALS）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking2\n",
    "ALS进行矩阵分解的时候，为什么可以并行化处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：由于ALS每次固定一个变量，更新另一个，如固定$Y$，$X$的更新表达式为$$ X_i = (YY^T + \\lambda I)^{-1} YR_i$$&emsp;&emsp;其中$X_i$为用户$i$的向量，为k维列向量，$Y=[Y_1,Y_2...Y_M]$为商品矩阵，$R_i$为用户$i$评分向量，为m维列向量（评分矩阵：$R=[R_1,R_2...R_N]^T$）  \n",
    "&emsp;&emsp;也就是说，用户矩阵$X=[X_1,X_2...X_N]$中每一个列向量的更新之和$Y$与$R$中对应的一行有关，相互之间是独立的，所以可以并行化处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking3\n",
    "梯度下降法中的批量梯度下降（BGD），随机梯度下降（SGD），和小批量梯度下降有什么区别（MBGD）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：批量梯度下降是每次都使用全体样本来对参数进行更新，随机梯度下降是每次随机选取一个样本对参数进行更新，小批量梯度下降是每次随机选取部分样本来对参数进行更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thinking4\n",
    "你阅读过和推荐系统/计算广告/预测相关的论文么？有哪些论文是你比较推荐的，可以分享到微信群中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：Restricted Boltzmann Machines for Collaborative Filtering——将受限的玻尔兹曼机用在协同过滤上，一个用户作为一个样本，将其每一个评分平铺成向量，形成评分矩阵输入，每个样本只影响有评分处的参数，模型训练完成后，并非是采用隐藏层得到的输出来计算相似度，而是直接利用编码再解码重构得到的评分矩阵来计算未评分处的评分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action1\n",
    "对MovieLens数据集进行评分预测\n",
    "工具：可以使用Surprise或者其他\n",
    "说明使用的模型，及简要原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用模型：BaselineModel  \n",
    "原理：将所有电影的均分$\\mu$加上用户对整体偏差$b_u$加上商品对整体的偏差$b_i$，得到预测值$b=\\mu+b_u+b_i$，然后对评分减预测值的平方和再加上正则化项进行优化，优化方法可用交替最小二乘法（ALS)，也可用随机梯度下降法（SGD）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1        2     3.5  1112486027\n",
      "1       1       29     3.5  1112484676\n",
      "2       1       32     3.5  1112484819\n",
      "3       1       47     3.5  1112484727\n",
      "4       1       50     3.5  1112484580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 3.5),\n",
       " (1, 3.5),\n",
       " (2, 3.5),\n",
       " (3, 3.5),\n",
       " (4, 3.5),\n",
       " (5, 3.5),\n",
       " (6, 4.0),\n",
       " (7, 4.0),\n",
       " (8, 4.0),\n",
       " (9, 4.0),\n",
       " (10, 4.0),\n",
       " (11, 4.0),\n",
       " (12, 4.0),\n",
       " (13, 3.5),\n",
       " (14, 3.5),\n",
       " (15, 4.0),\n",
       " (16, 3.5),\n",
       " (17, 3.5),\n",
       " (18, 3.0),\n",
       " (19, 3.5),\n",
       " (20, 3.5),\n",
       " (21, 3.5),\n",
       " (22, 4.0),\n",
       " (23, 4.0),\n",
       " (24, 3.5),\n",
       " (25, 3.5),\n",
       " (26, 4.0),\n",
       " (27, 4.0),\n",
       " (28, 3.5),\n",
       " (29, 3.5),\n",
       " (30, 4.5),\n",
       " (31, 4.5),\n",
       " (32, 4.0),\n",
       " (33, 3.0),\n",
       " (34, 3.5),\n",
       " (35, 4.0),\n",
       " (36, 4.0),\n",
       " (37, 3.5),\n",
       " (38, 4.0),\n",
       " (39, 3.5),\n",
       " (40, 4.0),\n",
       " (41, 3.0),\n",
       " (42, 3.5),\n",
       " (43, 4.0),\n",
       " (44, 4.0),\n",
       " (45, 4.0),\n",
       " (46, 3.5),\n",
       " (47, 3.5),\n",
       " (48, 4.0),\n",
       " (49, 4.0),\n",
       " (50, 3.5),\n",
       " (51, 3.0),\n",
       " (52, 4.0),\n",
       " (53, 4.0),\n",
       " (54, 3.5),\n",
       " (55, 3.5),\n",
       " (56, 4.0),\n",
       " (57, 3.0),\n",
       " (58, 4.0),\n",
       " (59, 4.0),\n",
       " (60, 3.0),\n",
       " (61, 3.5),\n",
       " (62, 3.5),\n",
       " (63, 3.5),\n",
       " (64, 3.5),\n",
       " (65, 4.0),\n",
       " (66, 3.5),\n",
       " (67, 3.5),\n",
       " (68, 4.0),\n",
       " (69, 4.0),\n",
       " (70, 4.0),\n",
       " (71, 4.0),\n",
       " (72, 4.0),\n",
       " (73, 4.0),\n",
       " (74, 4.0),\n",
       " (75, 4.0),\n",
       " (76, 4.0),\n",
       " (77, 3.5),\n",
       " (78, 3.5),\n",
       " (79, 4.0),\n",
       " (80, 4.0),\n",
       " (81, 4.0),\n",
       " (82, 4.0),\n",
       " (83, 3.5),\n",
       " (84, 3.5),\n",
       " (85, 3.5),\n",
       " (86, 3.5),\n",
       " (87, 3.5),\n",
       " (88, 3.5),\n",
       " (89, 3.0),\n",
       " (90, 4.0),\n",
       " (91, 3.5),\n",
       " (92, 4.0),\n",
       " (93, 3.5),\n",
       " (94, 4.0),\n",
       " (95, 3.5),\n",
       " (96, 4.0),\n",
       " (97, 4.0),\n",
       " (98, 3.5),\n",
       " (99, 3.0),\n",
       " (100, 3.5),\n",
       " (101, 4.0),\n",
       " (102, 4.0),\n",
       " (103, 3.5),\n",
       " (104, 3.5),\n",
       " (105, 3.5),\n",
       " (106, 4.0),\n",
       " (107, 4.0),\n",
       " (108, 4.0),\n",
       " (109, 4.0),\n",
       " (110, 3.0),\n",
       " (111, 4.0),\n",
       " (112, 3.5),\n",
       " (113, 4.0),\n",
       " (114, 4.0),\n",
       " (115, 3.5),\n",
       " (116, 4.0),\n",
       " (117, 3.0),\n",
       " (118, 3.5),\n",
       " (119, 4.0),\n",
       " (120, 3.5),\n",
       " (121, 4.0),\n",
       " (122, 4.0),\n",
       " (123, 3.5),\n",
       " (124, 4.0),\n",
       " (125, 3.5),\n",
       " (126, 4.0),\n",
       " (127, 4.0),\n",
       " (128, 3.0),\n",
       " (129, 3.5),\n",
       " (130, 3.5),\n",
       " (131, 5.0),\n",
       " (132, 4.0),\n",
       " (133, 4.0),\n",
       " (134, 3.0),\n",
       " (135, 3.5),\n",
       " (136, 4.0),\n",
       " (137, 4.0),\n",
       " (138, 3.5),\n",
       " (139, 4.0),\n",
       " (140, 4.0),\n",
       " (141, 3.5),\n",
       " (142, 5.0),\n",
       " (143, 3.5),\n",
       " (144, 4.0),\n",
       " (145, 3.5),\n",
       " (146, 4.0),\n",
       " (147, 3.5),\n",
       " (148, 4.0),\n",
       " (149, 4.0),\n",
       " (150, 3.5),\n",
       " (151, 4.0),\n",
       " (152, 3.5),\n",
       " (153, 3.5),\n",
       " (154, 3.0),\n",
       " (155, 3.5),\n",
       " (156, 3.5),\n",
       " (157, 4.0),\n",
       " (158, 5.0),\n",
       " (159, 3.5),\n",
       " (160, 3.5),\n",
       " (161, 3.5),\n",
       " (162, 4.0),\n",
       " (163, 4.0),\n",
       " (164, 3.5),\n",
       " (165, 4.0),\n",
       " (166, 3.0),\n",
       " (167, 4.0),\n",
       " (168, 4.0),\n",
       " (169, 3.5),\n",
       " (170, 5.0),\n",
       " (171, 4.5),\n",
       " (172, 3.5),\n",
       " (173, 4.0),\n",
       " (174, 4.0)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader\n",
    "\n",
    "# 数据加载\n",
    "pd_data = pd.read_csv('./ratings.csv')\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
    "data = Dataset.load_from_file('./ratings.csv', reader=reader)\n",
    "#也可以load_from_df\n",
    "train_set = data.build_full_trainset()\n",
    "\n",
    "# 数据探索（查询user 0)\n",
    "print(pd_data.head())\n",
    "train_set.ur[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对于ALS：\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8649\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8632\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8634\n",
      "k折交叉验证的平均准确率为： 0.8638121264775914\n",
      "平均用时为： 4.647355794906616\n",
      "对于SGD：\n",
      "Estimating biases using sgd...\n",
      "RMSE: 0.8746\n",
      "Estimating biases using sgd...\n",
      "RMSE: 0.8731\n",
      "Estimating biases using sgd...\n",
      "RMSE: 0.8752\n",
      "k折交叉验证的平均准确率为： 0.8742830718392947\n",
      "平均用时为： 4.42904535929362\n"
     ]
    }
   ],
   "source": [
    "from surprise import BaselineOnly\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import accuracy\n",
    "import time\n",
    "\n",
    "# ALS\n",
    "als = {'method': 'als', 'n_epochs': 5, 'reg_u': 12, 'reg_i': 5}\n",
    "#SGD\n",
    "sgd = {'method': 'sgd', 'n_epochs': 5}\n",
    "\n",
    "algo_als = BaselineOnly(bsl_options=als)\n",
    "algo_sgd = BaselineOnly(bsl_options=sgd)\n",
    "\n",
    "# 定义K折交叉验证\n",
    "def kfold(data, algo, k=3):\n",
    "    kf = KFold(n_splits=k)\n",
    "    sum_arr = 0\n",
    "    start = time.time()\n",
    "    for trainset, testset in kf.split(data):\n",
    "        algo.fit(trainset)\n",
    "        predictions = algo.test(testset)\n",
    "        # 计算RMSE\n",
    "        sum_arr += accuracy.rmse(predictions, verbose=True)\n",
    "    end = time.time()\n",
    "    return sum_arr/k, (end-start)/k\n",
    "\n",
    "print('对于ALS：')\n",
    "arr, t = kfold(data, algo_als)\n",
    "print('k折交叉验证的平均准确率为：',arr)\n",
    "print('平均用时为：',t)\n",
    "\n",
    "print('对于SGD：')\n",
    "arr, t = kfold(data, algo_sgd)\n",
    "print('k折交叉验证的平均准确率为：',arr)\n",
    "print('平均用时为：',t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对于User 0的top5推荐为：\n",
      "Estimating biases using sgd...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(60524, 3.5292716305462175),\n",
       " (70227, 3.5292716305462175),\n",
       " (59382, 3.5292716305462175),\n",
       " (60482, 3.5292716305462175),\n",
       " (2489, 3.5292716305462175)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推荐topN\n",
    "movies = list(pd_data['movieId'].drop_duplicates(keep=False))\n",
    "def recommander(uid, trainset, movielist, algo, n=5):\n",
    "    algo.fit(trainset)\n",
    "    result = {}\n",
    "    rated = [i[0] for i in train_set.ur[uid]]\n",
    "    for iid in movielist:\n",
    "        if iid in rated:\n",
    "            continue\n",
    "        pred = algo.predict(uid,iid)[3]\n",
    "        result[iid] = pred\n",
    "    return sorted(result.items(), key = lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "print('对于User 0的top5推荐为：')\n",
    "recommander(0, train_set, movies, algo_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action2\n",
    "Paper Reading：Slope one predictors for online rating-based collaborative filtering. Daniel Lemire and Anna Maclachlan, 2007. http://arxiv.org/abs/cs/0702144.\n",
    "积累，总结笔记，自己的思考及idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：  \n",
    "&emsp;&emsp;文章介绍了基础的Slope one算法，以及两种改进的Slope one——有权重的（the weighted slope one）以及根据划分喜恶的（the bi-polar slope one），并与几个有代表性的算法进行了效果比较，说明了slope one算法在具有易于实现、更新迅速、查询高效、对用户历史数据要求少这几个优点的同时，仍然具有有竞争性的准确性。  \n",
    "\n",
    "自己的思考：  \n",
    "&emsp;&emsp;除了Slope one的想法本身，文章介绍的第二种优化更加体现了协同过滤的思想，基于用户评分的平均值，将用户评过分的电影分为“用户喜欢”和“用户不喜欢”，并且以用户U，查询电影i为例，假设j为用户U喜欢的电影，在计入j对i的偏差值的时，只考虑那些同样喜欢j并且还喜欢i的用户，共同喜欢j代表了用户之间的相似，j和i被同时喜欢代表了电影间的相似，这里充分地体现了协同过滤的思想。一开始我认为应该将“相似”用户都算进去，但仔细想过之后发现要求这些用户对i、j同喜恶是有道理的，因为当人和人喜欢的东西相同时并不代表他们讨厌的东西也相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action3\n",
    "设计你自己的句子生成器  \n",
    "grammar = '''\n",
    "战斗 => 施法  ， 结果 。\n",
    "施法 => 主语 动作 技能 \n",
    "结果 => 主语 获得 效果\n",
    "主语 => 张飞 | 关羽 | 赵云 | 典韦 | 许褚 | 刘备 | 黄忠 | 曹操 | 鲁班七号 | 貂蝉\n",
    "动作 => 施放 | 使用 | 召唤 \n",
    "技能 => 一骑当千 | 单刀赴会 | 青龙偃月 | 刀锋铁骑 | 黑暗潜能 | 画地为牢 | 守护机关 | 狂兽血性 | 龙鸣 | 惊雷之龙 | 破云之龙 | 天翔之龙\n",
    "获得 => 损失 | 获得 \n",
    "效果 => 数值 状态\n",
    "数值 => 1 | 1000 |5000 | 100 \n",
    "状态 => 法力 | 生命\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = '''\n",
    "战斗 => 施法  ， 结果 。\n",
    "施法 => 主语 动作 技能 \n",
    "结果 => 主语 获得 效果\n",
    "主语 => 张飞 | 关羽 | 赵云 | 典韦 | 许褚 | 刘备 | 黄忠 | 曹操 | 鲁班七号 | 貂蝉\n",
    "动作 => 施放 | 使用 | 召唤 \n",
    "技能 => 一骑当千 | 单刀赴会 | 青龙偃月 | 刀锋铁骑 | 黑暗潜能 | 画地为牢 | 守护机关 | 狂兽血性 | 龙鸣 | 惊雷之龙 | 破云之龙 | 天翔之龙\n",
    "获得 => 损失 | 获得 \n",
    "效果 => 数值 状态\n",
    "数值 => 1 | 1000 |5000 | 100 \n",
    "状态 => 法力 | 生命\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'战斗': [['施法', '，', '结果', '。']],\n",
       " '施法': [['主语', '动作', '技能']],\n",
       " '结果': [['主语', '获得', '效果']],\n",
       " '主语': [['张飞'],\n",
       "  ['关羽'],\n",
       "  ['赵云'],\n",
       "  ['典韦'],\n",
       "  ['许褚'],\n",
       "  ['刘备'],\n",
       "  ['黄忠'],\n",
       "  ['曹操'],\n",
       "  ['鲁班七号'],\n",
       "  ['貂蝉']],\n",
       " '动作': [['施放'], ['使用'], ['召唤']],\n",
       " '技能': [['一骑当千'],\n",
       "  ['单刀赴会'],\n",
       "  ['青龙偃月'],\n",
       "  ['刀锋铁骑'],\n",
       "  ['黑暗潜能'],\n",
       "  ['画地为牢'],\n",
       "  ['守护机关'],\n",
       "  ['狂兽血性'],\n",
       "  ['龙鸣'],\n",
       "  ['惊雷之龙'],\n",
       "  ['破云之龙'],\n",
       "  ['天翔之龙']],\n",
       " '获得': [['损失'], ['获得']],\n",
       " '效果': [['数值', '状态']],\n",
       " '数值': [['1'], ['1000'], ['5000'], ['100']],\n",
       " '状态': [['法力'], ['生命']]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成语法树\n",
    "def getGrammardict(grammar, linesplit='\\n', gramsplit='=>'):\n",
    "    result = {}\n",
    "    for line in grammar.split(linesplit):\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        exp, statement = line.split(gramsplit)\n",
    "        result[exp.strip()] = [i.split() for i in statement.split('|')]\n",
    "    return result\n",
    "grammardict = getGrammardict(grammar)\n",
    "grammardict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'黄忠召唤破云之龙，关羽损失1法力。'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成句子\n",
    "import random\n",
    "def generate(grammardict, target, isEng=False):\n",
    "    if target not in grammardict:\n",
    "        return target\n",
    "    find = random.choice(grammardict[target])\n",
    "    blank =''\n",
    "    if isEng:\n",
    "        blank = ' '\n",
    "    return blank.join(generate(grammardict, i, isEng) for i in find)\n",
    "generate(grammardict, '战斗')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
